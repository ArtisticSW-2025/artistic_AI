# artistic_AI

[피드백 모델]

+ 경량화 모델 사용(1B) : https://huggingface.co/qixiangme/hospital-feedback1Bv1

   + CPU 60초 / GPU+양자화 40~50초

+ Blossom (Llama3 8B): https://huggingface.co/qixiangme/hospital-feedback_ver3

    + GPU + 양자화XXXX 

자세한 데이터 형식 및 테스트결과는 노션 이창민 작업현황에서 확인하실수있습니다


feedback.py, feedback_1B.py 둘다 같은 프롬프트 구성 방식을 가집니다

입력해야할 prompt 형식:

1. JSON 형식 -> 프롬프트 String 형식 으로 변환하는 로직입니다
   + 이건 테스트하기 이게 더 편해서 이렇게 한거고 중요한건 프롬프트 String 형식입니다
  
2. 프롬프트 형식은 시스템, 유저 , 어시스턴트로 구성됩니다

```
<|system|>

[system 메시지]

<|user|>

[대화 전문 포함된 user 메시지]

<|assistant|>

[=> 여기에 모델이 피드백 생성]
```

+ 시스템은 AI가 무엇을 해야하는 지 정의를 하는 부분입니다.
    + Training 할때 "너는 병원 예약 도우미 AI가 아닌, '사용자 피드백 코치'야. 아래 대화를 보고 유저가 표현을 개선하거나 주의할 점에 대해 피드백을 작성해줘. 피드백은 간단하게 해주고 능동성, 정확성, 예의 이 3가지 기준으로 점수 매겨줘." 이렇게 Training 했기 때문에 이는 고정시켜주기 바랇니다.
+ User에는 AI에게 줄 입력의 본 부분입니다. 피드백 모델에선 대화 전문을 넣어야합니다. 또한 이 대화 전문의 형식도 Training 데이터와 맞춰야합니다.
    + 처음에 -> "[대화 시작]"
    + 유저가 말한건 "User : [유저가 한 말] "
    + AI가 응답한건 "Assistant: [AI가 한 말] "
    + 대화가 끝날때까지 반복
    + 대화가 끝날때 -> "[대화 끝]"
+ assistant는 assistant가 응답하는 부분입니다.
    + Training 할때는 이 부분에 정답데이터(피드백 해주는 데이터)를 넣어줬지만, 추론(text 생성)할때는 이 부분을 비워줌으로서
    + 파인튜닝 된 AI가 "아 이제 피드백해주는 데이터가 들어갈 차례니 내가 이 빈 부분을 채워줘야겠다" 를 깨닫게 표시해줘야합니다.
 
+ 전체 예시
```
<|system|>
너는 병원 예약 도우미 AI가 아닌, '사용자 피드백 코치'야. 아래 대화를 보고 유저가 표현을 개선하거나 주의할 점에 대해 피드백을 작성해줘. 피드백은 간단하게 해주고 능동성, 정확성, 예의 이 3가지 기준으로 점수 매겨줘.
<|user|>
[대화 시작]
User: 안녕하세요, 수고 많으십니다. 오늘 오전 11시에 진료 예약된 홍길동(010-1234-5678)입니다. 갑작스러운 회사 일로 해당 시간에 방문이 어려워졌습니다. 혹시 오후 2시에서 4시 사이로 시간 조정이 가능할지 여쭙니다.
Assistant: 네, 홍길동 님. 확인해보겠습니다. 아, 마침 2시 30분에 취소 건이 하나 있습니다. 이 시간 괜찮으실까요?
User: 네! 정말 다행이네요. 2시 30분으로 변경 부탁드립니다. 배려해주셔서 정말 감사합니다.
[대화 끝]
<|assistant|>
```


[대화 생성 모델]

## model
1. 사용자가 대답한 음성을 텍스트로 변환하는 모델 - stt
2. 텍스트를 음성으로 변환 - tts
3. 사용자의 대답을 기반으로 다음 말을 이어나가는 모델 - 대화 생성 model finetuning
4. 사용자가 대답한 음성을 분석해주는 모델 (어조, 말투, 높낮이 등)
5. 전체적인 대화 맥락, 음성 분석 데이터를 보고 종합 평가 하는 모델 (전체적인 평가, 종합 점수, 개선점 등)

## 모의통화 흐름도
1. 상대 AI가 텍스트와 음성을 동시에 출력하며 첫 질문 또는 상황을 제시한다.
2. 사용자가 음성으로 대답한다.
3. STT(Speech-to-Text)를 이용해 음성을 문자로 바꾼다.
4. 변환된 텍스트가 채팅 말풍선 형태로 대화창에 표시된다.
5. 사용자의 발화를 기반으로 AI가 다음 응답을 생성한다.
6. TTS(Text-to-Speech)를 통해 AI의 응답 문장을 음성으로 변환한다.
7. AI의 응답이 텍스트와 음성으로 동시에 출력되고 대화창에 표시된다.
8. 2단계부터 7단계까지의 흐름이 반복된다. (종료 조건이 충족될 때까지 대화가 이어진다.)
9. 대화가 끝나면 전체 발화 내용이 분석된다.
- 말 속도, 어미 사용, 정중함, 끊김 여부 등 다양한 요소가 평가된다.
- 분석 결과를 바탕으로 종합 피드백이 제공된다.
- 분석 점수와 함께 시각적 피드백 및 향후 개선을 위한 맞춤형 연습 가이드가 제시된다.
